{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random, warnings, gc, psutil, datetime\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "\n",
    "# Set options\n",
    "pd.set_option('max_columns',500)\n",
    "pd.set_option('max_rows',500)\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus = pd.read_csv(path + 'bus_bts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus['geton_date'] = pd.to_datetime(df_bus['geton_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주중에 정기적으로 타는 사람들\n",
    "df_bus['weekday'] = df_bus['geton_date'].dt.weekday\n",
    "\n",
    "df_weekday = df_bus[df_bus['weekday']<5]\n",
    "\n",
    "df_commuter = df_weekday.groupby(['user_card_id','geton_station_code']).size().reset_index()\n",
    "df_commuter.columns = ['user_card_id','geton_station_code','num_usage']\n",
    "\n",
    "df_commuter = df_commuter[df_commuter['num_usage']>=10].reset_index(drop=True)\n",
    "df_commuter = df_commuter.groupby('geton_station_code')['user_card_id'].count()\n",
    "\n",
    "df_commuter = df_commuter.reset_index()\n",
    "df_commuter.columns = ['station_code','regular_commuter_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 정류장에 12시 이후에 몇명이 내렸는지\n",
    "df_afternoon = df_bus[df_bus['getoff_time']>='12:00:00'][['bus_route_id','getoff_date','getoff_station_code','getoff_time','user_category','user_count']]\n",
    "df_afternoon_getoff_amount = df_afternoon.groupby(['bus_route_id','getoff_date','getoff_station_code'])['user_count'].sum().reset_index()\n",
    "df_afternoon_getoff_amount = df_afternoon_getoff_amount.rename(columns = {'user_count' : 'afternoon_takeoff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 정류장에 같은 노선의 버스가 직전 몇분 전에 왔었는지\n",
    "first_passenger_tagtime = df_bus.groupby(['geton_date', 'bus_route_id', 'vhc_id','geton_station_code'])['geton_time'].min().reset_index()\n",
    "\n",
    "\n",
    "first_passenger_tagtime = first_passenger_tagtime.sort_values(by=['geton_date','bus_route_id','geton_station_code','geton_time']).reset_index(drop=True)\n",
    "\n",
    "first_passenger_tagtime['geton_time_second']= first_passenger_tagtime['geton_time'].apply(lambda x: 60*60 *int(x.split(':')[0] ) +\\\n",
    "                                                                                                    60 * int(x.split(':')[1]) +\\\n",
    "                                                                                                          int(x.split(':')[2]) )\n",
    "\n",
    "first_passenger_tagtime['next_bus_time_diff'] = first_passenger_tagtime.groupby(['geton_date','bus_route_id','geton_station_code'])['geton_time_second'].diff()\n",
    "date_route_stataion_waittime = first_passenger_tagtime.groupby(['geton_date','bus_route_id','geton_station_code'])['next_bus_time_diff'].mean().reset_index()\n",
    "\n",
    "date_route_stataion_waittime = date_route_stataion_waittime.groupby(['geton_date','bus_route_id'])['next_bus_time_diff'].mean()\n",
    "date_route_stataion_waittime =date_route_stataion_waittime.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6~9, 9~12시 사이에 각기 다른 집단의 사람들이 몇명 탑승했는지\n",
    "bus_sample = df_bus[['geton_date','geton_station_code','geton_time','user_category','user_count']].copy()\n",
    "bus_sample['geton_morning'] = bus_sample['geton_time'].apply(lambda x: int(x.split(':')[0]) <=9 )\n",
    "bus_passender_cluster_count = bus_sample.groupby(['geton_date','geton_station_code','geton_morning','user_category'])['user_count'].sum().reset_index()\n",
    "\n",
    "bus_passender_cluster_count_morning = bus_passender_cluster_count[bus_passender_cluster_count['geton_morning']==True]\n",
    "geton_bus_passender_cluster_count_morning = pd.pivot_table( bus_passender_cluster_count_morning, index = ['geton_date', 'geton_station_code'],\n",
    "                                columns=['user_category'], values = ['user_count'], aggfunc='sum').reset_index()\n",
    "\n",
    "geton_bus_passender_cluster_count_morning.columns = ['geton_date', 'geton_station_code']  +\\\n",
    "                            ['getin_user_count1_morning','getin_user_count2_morning','getin_user_count4_morning','getin_user_count6_morning','d1','d2','d3','d4']\n",
    "\n",
    "geton_bus_passender_cluster_count_morning = geton_bus_passender_cluster_count_morning.drop(['d1','d2','d3','d4'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_getoff_time(val):\n",
    "    if val <= 9 :\n",
    "        return 0\n",
    "    elif val <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6~9, 9~12시 사이에 각기 다른 집단의 사람들이 몇명 내렸는지\n",
    "bus_sample = df_bus[['geton_date','getoff_station_code','getoff_time','user_category','user_count']].copy()\n",
    "bus_sample = bus_sample[bus_sample['getoff_time'].notnull()]\n",
    "bus_sample['getoff_hour'] =  bus_sample['getoff_time'].apply(lambda x: int(x.split(':')[0]) )\n",
    "bus_sample['getoff_hour'] =  bus_sample['getoff_hour'].apply(calculate_getoff_time)\n",
    "\n",
    "bus_passender_cluster_count = bus_sample.groupby(['geton_date','getoff_station_code','getoff_hour','user_category'])['user_count'].sum().reset_index()\n",
    "\n",
    "takeoff_bus_passender_cluster_count_noon = bus_passender_cluster_count[bus_passender_cluster_count['getoff_hour']==1]\n",
    "\n",
    "\n",
    "takeoff_bus_passender_cluster_count_noon = pd.pivot_table( takeoff_bus_passender_cluster_count_noon, index = ['geton_date', 'getoff_station_code'],\n",
    "                                                                    columns=['user_category'], values = ['user_count'], aggfunc='sum').reset_index()\n",
    "\n",
    "\n",
    "\n",
    "takeoff_bus_passender_cluster_count_noon.columns = ['geton_date', 'getoff_station_code']  +\\\n",
    "                            ['takeoff_user_count1_noon','takeoff_user_count2_noon','takeoff_user_count4_noon','takeoff_user_count6_noon','d1','d2','d3','d4']\n",
    "\n",
    "takeoff_bus_passender_cluster_count_noon = takeoff_bus_passender_cluster_count_noon.drop(['d1','d2','d3','d4'],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+'train.csv', parse_dates =['date'])\n",
    "test = pd.read_csv(path+'test.csv', parse_dates =['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trn = len(train)\n",
    "target_col = '18~20_ride'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a whole dataset\n",
    "combined = train.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10~11_ride</th>\n",
       "      <th>10~11_takeoff</th>\n",
       "      <th>11~12_ride</th>\n",
       "      <th>11~12_takeoff</th>\n",
       "      <th>18~20_ride</th>\n",
       "      <th>6~7_ride</th>\n",
       "      <th>6~7_takeoff</th>\n",
       "      <th>7~8_ride</th>\n",
       "      <th>7~8_takeoff</th>\n",
       "      <th>8~9_ride</th>\n",
       "      <th>8~9_takeoff</th>\n",
       "      <th>9~10_ride</th>\n",
       "      <th>9~10_takeoff</th>\n",
       "      <th>bus_route_id</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>in_out</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4270000</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>시외</td>\n",
       "      <td>33.48990</td>\n",
       "      <td>126.49373</td>\n",
       "      <td>344</td>\n",
       "      <td>제주썬호텔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4270000</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>시외</td>\n",
       "      <td>33.48944</td>\n",
       "      <td>126.48508</td>\n",
       "      <td>357</td>\n",
       "      <td>한라병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4270000</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2</td>\n",
       "      <td>시외</td>\n",
       "      <td>33.48181</td>\n",
       "      <td>126.47352</td>\n",
       "      <td>432</td>\n",
       "      <td>정존마을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4270000</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>시내</td>\n",
       "      <td>33.50577</td>\n",
       "      <td>126.49252</td>\n",
       "      <td>1579</td>\n",
       "      <td>제주국제공항(600번)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4270000</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>시내</td>\n",
       "      <td>33.25579</td>\n",
       "      <td>126.41260</td>\n",
       "      <td>1646</td>\n",
       "      <td>중문관광단지입구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   10~11_ride  10~11_takeoff  11~12_ride  11~12_takeoff  18~20_ride  6~7_ride  \\\n",
       "0         2.0            0.0         6.0            0.0         0.0       0.0   \n",
       "1         5.0            0.0         6.0            0.0         5.0       1.0   \n",
       "2         0.0            0.0         0.0            0.0         2.0       1.0   \n",
       "3        14.0            0.0        16.0            0.0        53.0       0.0   \n",
       "4         0.0            0.0         0.0            0.0         0.0       0.0   \n",
       "\n",
       "   6~7_takeoff  7~8_ride  7~8_takeoff  8~9_ride  8~9_takeoff  9~10_ride  \\\n",
       "0          0.0       1.0          0.0       2.0          0.0        5.0   \n",
       "1          0.0       4.0          0.0       4.0          0.0        2.0   \n",
       "2          0.0       1.0          0.0       0.0          0.0        2.0   \n",
       "3          0.0      17.0          0.0       6.0          0.0       26.0   \n",
       "4          0.0       0.0          0.0       0.0          0.0        0.0   \n",
       "\n",
       "   9~10_takeoff  bus_route_id       date  id in_out  latitude  longitude  \\\n",
       "0           0.0       4270000 2019-09-01   0     시외  33.48990  126.49373   \n",
       "1           0.0       4270000 2019-09-01   1     시외  33.48944  126.48508   \n",
       "2           0.0       4270000 2019-09-01   2     시외  33.48181  126.47352   \n",
       "3           0.0       4270000 2019-09-01   3     시내  33.50577  126.49252   \n",
       "4           1.0       4270000 2019-09-01   4     시내  33.25579  126.41260   \n",
       "\n",
       "   station_code  station_name  \n",
       "0           344         제주썬호텔  \n",
       "1           357          한라병원  \n",
       "2           432          정존마을  \n",
       "3          1579  제주국제공항(600번)  \n",
       "4          1646      중문관광단지입구  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence of the station\n",
    "combined['station_sequence'] = 1\n",
    "combined['station_reverse_sequence'] = combined[::-1].groupby(['date','bus_route_id'])['station_sequence'].cumsum()[::-1]\n",
    "combined['station_sequence'] = combined.groupby(['date','bus_route_id'])['station_sequence'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dtype of \"date\"\n",
    "combined['weekday'] = combined['date'].dt.weekday.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays\n",
    "national_holidays = [datetime.date(2019, 9,12),datetime.date(2019, 9,13), datetime.date(2019, 9,14),\n",
    "                        datetime.date(2019, 10,3), datetime.date(2019, 10,9)]\n",
    "combined['is_national_holiday'] = combined['date'].apply(lambda x: x in national_holidays).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum-up the number of passengers for two intervers\n",
    "morining_getin_cols = ['6~7_ride', '7~8_ride', '8~9_ride']\n",
    "noon_getin_cols = ['9~10_ride', '10~11_ride', '11~12_ride']\n",
    "\n",
    "morning_takeoff_cols = ['6~7_takeoff', '7~8_takeoff','8~9_takeoff']\n",
    "noon_takeoff_cols = ['9~10_takeoff', '10~11_takeoff', '11~12_takeoff']\n",
    "\n",
    "# Morning getin/takeoff & Noon getin/takeoff\n",
    "combined['morning_getin'] = combined[morining_getin_cols].sum(axis=1)\n",
    "combined['morning_takeoff'] = combined[morning_takeoff_cols].sum(axis=1)\n",
    "\n",
    "combined['noon_getin'] = combined[noon_getin_cols].sum(axis=1)\n",
    "combined['noon_takeoff'] = combined[noon_takeoff_cols].sum(axis=1)\n",
    "\n",
    "combined = combined.drop(morining_getin_cols  + noon_getin_cols + morning_takeoff_cols + noon_takeoff_cols ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATION_CODE\n",
    "\n",
    "# Sum of passenger per morning (getin)  \n",
    "station_morning_getin_sum = combined.groupby(['date','station_code'])['morning_getin'].sum().reset_index()\n",
    "station_morning_getin_sum = station_morning_getin_sum.rename(columns = {'morning_getin': 'station_morning_getin_sum'})\n",
    "\n",
    "# Sum of passenger per morning (takeoff)  \n",
    "station_morning_takeoff_sum = combined.groupby(['date','station_code'])['morning_takeoff'].sum().reset_index()\n",
    "station_morning_takeoff_sum = station_morning_takeoff_sum.rename(columns = {'morning_takeoff': 'station_morning_takeoff_sum'})\n",
    "\n",
    "# Merge\n",
    "combined = pd.merge(combined, station_morning_getin_sum , on =['date','station_code'], how='left')\n",
    "combined = pd.merge(combined, station_morning_takeoff_sum , on =['date','station_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUS_ROUTE\n",
    "\n",
    "# Sum of passenger per morning (getin)  \n",
    "bus_route_getin_sum = combined.groupby(['date','bus_route_id'])['morning_getin'].sum().reset_index()\n",
    "bus_route_getin_sum = bus_route_getin_sum.rename(columns = {'morning_getin': 'bus_route_getin_sum'})\n",
    "\n",
    "# Sum of passenger per morning (takeoff)  \n",
    "bus_route_takeoff_sum = combined.groupby(['date','bus_route_id'])['morning_takeoff'].sum().reset_index()\n",
    "bus_route_takeoff_sum = bus_route_takeoff_sum.rename(columns = {'morning_takeoff': 'bus_route_takeoff_sum'})\n",
    "\n",
    "# Merge\n",
    "combined = pd.merge(combined, bus_route_getin_sum , on =['date','bus_route_id'], how='left')\n",
    "combined = pd.merge(combined, bus_route_takeoff_sum , on =['date','bus_route_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATION_CODE\n",
    "\n",
    "# mean of passenger per morning (getin)  -- noon getin not working\n",
    "station_morning_getin_mean = combined.groupby(['date','station_code'])['morning_getin'].mean().reset_index()\n",
    "station_morning_getin_mean = station_morning_getin_mean.rename(columns = {'morning_getin': 'station_morning_getin_mean'})\n",
    "\n",
    "# mean of passenger per morning (getin)  -- noon getin not working\n",
    "station_morning_takeoff_mean = combined.groupby(['date','station_code'])['morning_takeoff'].mean().reset_index()\n",
    "station_morning_takeoff_mean = station_morning_takeoff_mean.rename(columns = {'morning_takeoff': 'station_morning_takeoff_mean'})\n",
    "\n",
    "# Merge\n",
    "combined = pd.merge(combined, station_morning_getin_mean , on =['date','station_code'], how='left')\n",
    "combined = pd.merge(combined, station_morning_takeoff_mean , on =['date','station_code'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUS_ROUTE\n",
    "\n",
    "# mean of passenger per morning (getin)  \n",
    "bus_route_getin_mean = combined.groupby(['date','bus_route_id'])['morning_getin'].mean().reset_index()\n",
    "bus_route_getin_mean = bus_route_getin_mean.rename(columns = {'morning_getin': 'bus_route_getin_mean'})\n",
    "\n",
    "# mean of passenger per morning (takeoff)  \n",
    "bus_route_takeoff_mean = combined.groupby(['date','bus_route_id'])['morning_takeoff'].mean().reset_index()\n",
    "bus_route_takeoff_mean = bus_route_takeoff_mean.rename(columns = {'morning_takeoff': 'bus_route_takeoff_mean'})\n",
    "\n",
    "# Merge\n",
    "combined = pd.merge(combined, bus_route_getin_mean , on =['date','bus_route_id'], how='left')\n",
    "combined = pd.merge(combined, bus_route_takeoff_mean , on =['date','bus_route_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans\n",
    "\n",
    "combined['bus_route_station'] = combined['bus_route_id'].astype(np.str)+'_'+combined['station_code'].astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "# Kmeans1\n",
    "df_cluster = combined[['date','bus_route_id','station_code','morning_getin']].copy()\n",
    "df_cluster['bus_route_station'] = df_cluster['bus_route_id'].astype(np.str)+'_'+df_cluster['station_code'].astype(np.str)\n",
    "df_cluster_pivot = pd.pivot_table(data = df_cluster, index='bus_route_station', columns='date',\n",
    "                                  values='morning_getin', aggfunc='sum').fillna(0)\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=200, random_state=1993)\n",
    "\n",
    "%time kmeans.fit(df_cluster_pivot)\n",
    "\n",
    "df_cluster_pivot['kmeans1'] = kmeans.predict(df_cluster_pivot)\n",
    "\n",
    "combined = pd.merge(combined, df_cluster_pivot[['kmeans1']], left_on = 'bus_route_station', right_index=True, \n",
    "                   how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 536 ms\n"
     ]
    }
   ],
   "source": [
    "# Kmeans2\n",
    "df_cluster = combined[['date','bus_route_id','station_code','noon_getin']].copy()\n",
    "df_cluster['bus_route_station'] = df_cluster['bus_route_id'].astype(np.str)+'_'+df_cluster['station_code'].astype(np.str)\n",
    "df_cluster_pivot = pd.pivot_table(data = df_cluster, index='bus_route_station', columns='date',\n",
    "                                  values='noon_getin', aggfunc='sum').fillna(0)\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=200, random_state=1993)\n",
    "\n",
    "%time kmeans.fit(df_cluster_pivot)\n",
    "\n",
    "df_cluster_pivot['kmeans2'] = kmeans.predict(df_cluster_pivot)\n",
    "\n",
    "combined = pd.merge(combined, df_cluster_pivot[['kmeans2']], left_on = 'bus_route_station', right_index=True, \n",
    "                   how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \n",
    "combined = pd.merge(combined, df_commuter, on = 'station_code',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Afternoon-Getoff-Amount\n",
    "df_afternoon_getoff_amount['getoff_date'] = pd.to_datetime(df_afternoon_getoff_amount['getoff_date'] )\n",
    "combined = pd.merge(combined, df_afternoon_getoff_amount,\n",
    "                 left_on = ['bus_route_id','date','station_code'],\n",
    "                 right_on = ['bus_route_id','getoff_date','getoff_station_code'],\n",
    "                 how='left')\n",
    "\n",
    "combined = combined.drop(['getoff_date','getoff_station_code'], 1)\n",
    "combined['afternoon_takeoff'] = combined['afternoon_takeoff'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 버스와의 배차간격?\n",
    "date_route_stataion_waittime['geton_date'] = pd.to_datetime(date_route_stataion_waittime['geton_date'] )\n",
    "combined = pd.merge(combined, date_route_stataion_waittime, \n",
    "                                         left_on =['date','bus_route_id'] ,\n",
    "                                         right_on =['geton_date','bus_route_id'],\n",
    "                                             how='left')\n",
    "combined = combined.drop(['geton_date'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6~9, 9~12시 사이에 각기 다른 집단의 사람들이 몇명 탑승했는지\n",
    "geton_bus_passender_cluster_count_morning['geton_date'] = pd.to_datetime(geton_bus_passender_cluster_count_morning['geton_date'] )\n",
    "combined = pd.merge( combined, geton_bus_passender_cluster_count_morning , left_on = ['date','station_code'],\n",
    "                                         right_on = ['geton_date', 'geton_station_code'],\n",
    "                                         how = 'left')\n",
    "\n",
    "combined = combined.drop(['geton_station_code','geton_date'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6~9, 9~12시 사이에 각기 다른 집단의 사람들이 몇명 내렸는지\n",
    "takeoff_bus_passender_cluster_count_noon['geton_date'] = pd.to_datetime(takeoff_bus_passender_cluster_count_noon['geton_date'] )\n",
    "combined = pd.merge( combined, takeoff_bus_passender_cluster_count_noon , left_on = ['date','station_code'],\n",
    "                                                                         right_on = ['geton_date', 'getoff_station_code'],\n",
    "                                                                         how = 'left')\n",
    "\n",
    "combined = combined.drop(['getoff_station_code','geton_date'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상데이터 -- 12시 전에 수집된 강수량\n",
    "df_rain = pd.read_csv('../preprocessed_external_dataset/hourly_rain.csv')\n",
    "df_rain['date'] = pd.to_datetime(df_rain['date'])\n",
    "\n",
    "combined = pd.merge(combined, df_rain, on='date', how='left')\n",
    "\n",
    "# 기상데이터 -- 전날 강수량\n",
    "df_daily_rain = pd.read_csv('../preprocessed_external_dataset/daily_rain.csv')\n",
    "df_daily_rain['date'] = pd.to_datetime(df_daily_rain['date'])\n",
    "df_daily_rain.columns = ['prev_date','prev_daily_rain']\n",
    "\n",
    "combined['prev_date'] = pd.to_datetime(combined['date']) - pd.Timedelta('1 day')\n",
    "combined = pd.merge(combined, df_daily_rain, on='prev_date', how='left')\n",
    "\n",
    "# 기상데이터 -- 12시 전에 수집된 운집량\n",
    "df_cloud = pd.read_csv('../preprocessed_external_dataset/hourly_cloud.csv')\n",
    "df_cloud['date'] = pd.to_datetime(df_rain['date'])\n",
    "\n",
    "combined = pd.merge(combined, df_cloud, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google-Map을 통한 정류장의 주소정보\n",
    "# 위경도 좌표를 입력값으로 해당 좌표의 주소를 크롤링한 pickle파일입니다.\n",
    "geo_df2 = pd.read_pickle('../preprocessed_external_dataset/second_whole_dict.pickle')\n",
    "combined['latlong_second'] = combined['latitude'].astype(np.str) +'_'+ combined['longitude'].astype(np.str)\n",
    "combined['latlong_second'] = combined['latlong_second'].apply(lambda x: geo_df2.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 별 거주자 수\n",
    "df_pop = pd.read_csv('../preprocessed_external_dataset/제주도_거주자수.csv')\n",
    "combined['district'] = combined['latlong_second'].apply(lambda x: x.split(' ')[1].split(' ')[0])\n",
    "combined = pd.merge(combined, df_pop, on='district', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "drop_cols = ['id','date', 'station_name','bus_route_station',] +\\\n",
    "                ['getin_user_count4_morning', 'takeoff_user_count4_noon', 'getin_user_count6_morning', 'takeoff_user_count6_noon',\n",
    "                'prev_date','district',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = combined[:n_trn].drop(drop_cols,1) , combined[n_trn:].drop(drop_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('preprocessed_train.pickle')\n",
    "test.to_pickle('preprocessed_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2013e1ecfede4ea59e91c287f0a3da93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "cat_cols = ['bus_route_id','station_code','in_out','latlong_second'\n",
    "            ]\n",
    "\n",
    "for col in tqdm_notebook(cat_cols):\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit( train[col].tolist() + test[col].tolist() )\n",
    "    train[col] = lbl.transform( train[[col]]  )\n",
    "    test[col] = lbl.transform( test[[col]]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before modeling\n",
    "train_set = train.drop([target_col]+[],1)\n",
    "test_set = test.drop([target_col]+[],1)\n",
    "\n",
    "train_label = train[target_col]\n",
    "test_label = test[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic LGBM Model\n",
    "n_splits= 5\n",
    "NUM_BOOST_ROUND = 100000\n",
    "SEED = 1993\n",
    "lgbm_param = {'objective':'rmse',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'random_state':1993,\n",
    "              'learning_rate':0.01,\n",
    "              'subsample':0.7,\n",
    "              'tree_learner': 'serial',\n",
    "              'colsample_bytree':0.78,\n",
    "              'early_stopping_rounds':50,\n",
    "              'subsample_freq': 1,\n",
    "              'reg_lambda':7,\n",
    "              'reg_alpha': 5,\n",
    "              'num_leaves': 96,\n",
    "              'seed' : SEED\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1683aff0a94b77a78d1ce7b2c322c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6738fe22404e46088d06da14401b3d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttrain's rmse: 2.94329\tvalid's rmse: 2.89743\n",
      "[200]\ttrain's rmse: 2.32829\tvalid's rmse: 2.38356\n",
      "[300]\ttrain's rmse: 2.08703\tvalid's rmse: 2.22306\n",
      "[400]\ttrain's rmse: 1.96039\tvalid's rmse: 2.1634\n",
      "[500]\ttrain's rmse: 1.87659\tvalid's rmse: 2.13815\n",
      "[600]\ttrain's rmse: 1.81553\tvalid's rmse: 2.1249\n"
     ]
    }
   ],
   "source": [
    "seeds = [1993]\n",
    "\n",
    "outer_oof_train = np.zeros( train.shape[0] )\n",
    "outer_oof_test = np.zeros( test.shape[0] )\n",
    "\n",
    "for seed in tqdm_notebook(seeds):\n",
    "    \n",
    "    cv_list = []\n",
    "\n",
    "    oof_train = np.zeros( train.shape[0] )\n",
    "    final_test = np.zeros( test.shape[0] )\n",
    "\n",
    "    kfolds = StratifiedKFold(n_splits = n_splits, shuffle=True, random_state=seed )\n",
    "\n",
    "    for ind, (trn_ind, val_ind) in tqdm_notebook( enumerate(kfolds.split(train_set, train_set['bus_route_id'])) ):\n",
    "\n",
    "        X_train, y_train = train_set.iloc[trn_ind], train_label[trn_ind]\n",
    "        X_valid, y_valid = train_set.iloc[val_ind], train_label[val_ind]\n",
    "        \n",
    "        dtrain = lgbm.Dataset( X_train, y_train )\n",
    "        dvalid = lgbm.Dataset( X_valid, y_valid ,reference=dtrain)\n",
    "        \n",
    "        lgbm_param['seed'] = seed\n",
    "\n",
    "        model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, valid_sets=(dtrain, dvalid), valid_names=('train','valid'), \n",
    "                            categorical_feature=['bus_route_id','station_code','weekday',\\\n",
    "                                                'kmeans1','kmeans2',\n",
    "#                                                  'latlong_second'\n",
    "#                                               'route_kmeans_cluster',\n",
    "                                                ] ,\n",
    "                           verbose_eval= 100)\n",
    "\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        test_pred  = model.predict(test_set)\n",
    "\n",
    "        oof_train[val_ind] += valid_pred\n",
    "        final_test += test_pred\n",
    "\n",
    "        cv_list.append( sqrt(mean_squared_error(y_valid, valid_pred)) )\n",
    "\n",
    "        print('='*80)\n",
    "\n",
    "    final_test /= n_splits\n",
    "\n",
    "    print(f\"Average CV : {np.mean(cv_list)}\")\n",
    "    print(f\"RMSE for OOF: {sqrt(mean_squared_error(train_label, oof_train))}\")\n",
    "    \n",
    "    outer_oof_train += oof_train\n",
    "    outer_oof_test += final_test\n",
    "    \n",
    "outer_oof_train /= len(seeds)\n",
    "outer_oof_test /= len(seeds)\n",
    "\n",
    "print(f\"Overall for OOF: {sqrt(mean_squared_error(train_label, outer_oof_train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame(data = {'col': model.feature_name(),\n",
    "                              'imp': model.feature_importance()\n",
    "                              })\n",
    "df_imp = df_imp.sort_values(by='imp', ascending=False)\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train = [x if x>0 else 0 for x in  oof_train]\n",
    "final_test = [x if x>0 else 0 for x in  final_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE for OOF: {sqrt(mean_squared_error(train_label, oof_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot( np.log1p( train_label ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot( np.log1p( oof_train ) )\n",
    "sns.distplot( np.log1p( final_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(path + 'submission_sample.csv')\n",
    "df_sub['18~20_ride'] = final_test\n",
    "\n",
    "df_sub.to_csv('ggg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
